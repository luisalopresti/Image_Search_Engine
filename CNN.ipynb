{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22624,
     "status": "ok",
     "timestamp": 1623542987326,
     "user": {
      "displayName": "Gioia Tessarolo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GijRfw_yfRjEGS-2dE-CXAEkkm6hlh4NL8oP0b5=s64",
      "userId": "06500016584956016487"
     },
     "user_tz": -120
    },
    "id": "5gpwK-Yvvu6r",
    "outputId": "535b004a-9b61-4210-c940-0e576ff37cc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1HAs5hhcsuFt"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
    "\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy import spatial\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "46PQdDJLNA4W"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Dataset(object):\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        assert os.path.exists(self.data_path), 'Insert a valid path!'\n",
    "\n",
    "        # get class list\n",
    "        self.data_classes = os.listdir(self.data_path)\n",
    "\n",
    "        # init mapping dict\n",
    "        self.data_mapping = {}\n",
    "\n",
    "        # populate mapping dict\n",
    "        for c, c_name in enumerate(self.data_classes):\n",
    "            temp_path = os.path.join(self.data_path, c_name)\n",
    "            temp_images = os.listdir(temp_path)\n",
    "\n",
    "            for i in temp_images:\n",
    "                img_tmp = os.path.join(temp_path, i)\n",
    "\n",
    "                if img_tmp.endswith('.jpg'):\n",
    "                    if c_name == 'distractor':\n",
    "                        self.data_mapping[img_tmp] = -1\n",
    "                    else:\n",
    "                        self.data_mapping[img_tmp] = int(c_name)\n",
    "\n",
    "        print('Loaded {:d} from {:s} images'.format(len(self.data_mapping.keys()),\n",
    "                                                    self.data_path))\n",
    "\n",
    "    def get_data_paths(self):\n",
    "        # returns a list of imgpaths and related classes\n",
    "        images = []\n",
    "        classes = []\n",
    "        for img_path in self.data_mapping.keys():\n",
    "            if img_path.endswith('.jpg'):\n",
    "                images.append(img_path)\n",
    "                classes.append(self.data_mapping[img_path])\n",
    "        return images, np.array(classes)\n",
    "\n",
    "\n",
    "    def num_classes(self):\n",
    "        # returns number of classes of the dataset\n",
    "        return len(self.data_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SM4Dbbdttno2"
   },
   "outputs": [],
   "source": [
    "# we get data_path\n",
    "data_path = '/content/drive/MyDrive/AML_Challange/dataset'\n",
    "# we define training_path\n",
    "training_path = os.path.join(data_path, 'training')\n",
    "\n",
    "# we define validation path, query and gallery\n",
    "validation_path = os.path.join(data_path, 'validation')\n",
    "gallery_path = os.path.join(validation_path, 'gallery')\n",
    "query_path = os.path.join(validation_path, 'query')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 94634,
     "status": "ok",
     "timestamp": 1623543096037,
     "user": {
      "displayName": "Gioia Tessarolo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GijRfw_yfRjEGS-2dE-CXAEkkm6hlh4NL8oP0b5=s64",
      "userId": "06500016584956016487"
     },
     "user_tz": -120
    },
    "id": "hsf27mTaYfV6",
    "outputId": "061fb500-d0e8-437f-c7ec-1a4f4ba88390"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 49553 images belonging to 22 classes.\n",
      "Found 604 images belonging to 2 classes.\n",
      "Found 70 images belonging to 14 classes.\n",
      "Found 534 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#All images are rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator( rescale= 1.0/255.)\n",
    "validation_datagen = ImageDataGenerator( rescale= 1.0/255.)\n",
    "query_datagen = ImageDataGenerator (rescale= 1.0/255.)\n",
    "gallery_datagen = ImageDataGenerator( rescale= 1.0/255.)\n",
    "\n",
    "\n",
    "\n",
    "train_generator =train_datagen.flow_from_directory(training_path,                                                \n",
    "                                                    batch_size=20,\n",
    "                                                   \n",
    "                                                    target_size = (224,224))\n",
    "\n",
    "                                                   \n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_path,\n",
    "                                                       batch_size=20,\n",
    "                                                      class_mode =None,\n",
    "                                                       target_size = (224,224))\n",
    "                                                        \n",
    "\n",
    "query_generator = query_datagen.flow_from_directory(query_path, \n",
    "                                                        batch_size=20,\n",
    "                                                        class_mode =None,\n",
    "                                                        target_size = (224,224))\n",
    "                                                       \n",
    "\n",
    "gallery_generator = gallery_datagen.flow_from_directory(gallery_path,\n",
    "                                                        batch_size=20,\n",
    "                                                        class_mode =None,\n",
    "                                                        target_size = (224,224))\n",
    "                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZ59Q9rnwD5X"
   },
   "outputs": [],
   "source": [
    " \n",
    "model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape =(224, 224, 3), padding='same'),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "      tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding='same'),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "      tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(1024, activation='relu'),\n",
    "      tf.keras.layers.Dense(22)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qXIerJZQ05Dn"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              #loss='sparse_categorical_crossentropy',\n",
    "              loss = keras.losses.categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1623519148300,
     "user": {
      "displayName": "Gioia Tessarolo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GijRfw_yfRjEGS-2dE-CXAEkkm6hlh4NL8oP0b5=s64",
      "userId": "06500016584956016487"
     },
     "user_tz": -120
    },
    "id": "gcrnXkX6euXx",
    "outputId": "18e232d6-0382-4db4-9a9a-8bb056d6bf08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 224, 224, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 112, 112, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              51381248  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 22)                22550     \n",
      "=================================================================\n",
      "Total params: 51,427,382\n",
      "Trainable params: 51,427,382\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8013978,
     "status": "ok",
     "timestamp": 1623554109046,
     "user": {
      "displayName": "Gioia Tessarolo",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GijRfw_yfRjEGS-2dE-CXAEkkm6hlh4NL8oP0b5=s64",
      "userId": "06500016584956016487"
     },
     "user_tz": -120
    },
    "id": "2CLR84S4X8P-",
    "outputId": "8e5d9cda-ec6f-4c78-871b-d11cb6e96d0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "50/50 [==============================] - 591s 12s/step - loss: 10.9764 - accuracy: 0.1860 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/15\n",
      "50/50 [==============================] - 562s 11s/step - loss: 11.0892 - accuracy: 0.2110 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/15\n",
      "50/50 [==============================] - 590s 12s/step - loss: 11.0409 - accuracy: 0.1850 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/15\n",
      "50/50 [==============================] - 580s 12s/step - loss: 10.7669 - accuracy: 0.1740 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/15\n",
      "50/50 [==============================] - 580s 12s/step - loss: 10.9120 - accuracy: 0.1950 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/15\n",
      "50/50 [==============================] - 550s 11s/step - loss: 10.6702 - accuracy: 0.1690 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/15\n",
      "50/50 [==============================] - 554s 11s/step - loss: 10.8958 - accuracy: 0.1990 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/15\n",
      "50/50 [==============================] - 523s 10s/step - loss: 10.5896 - accuracy: 0.1670 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/15\n",
      "50/50 [==============================] - 493s 10s/step - loss: 10.8314 - accuracy: 0.1750 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/15\n",
      "50/50 [==============================] - 474s 9s/step - loss: 11.0570 - accuracy: 0.1950 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/15\n",
      "50/50 [==============================] - 448s 9s/step - loss: 11.0570 - accuracy: 0.2160 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/15\n",
      "50/50 [==============================] - 463s 9s/step - loss: 10.7024 - accuracy: 0.1940 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/15\n",
      "50/50 [==============================] - 452s 9s/step - loss: 10.6863 - accuracy: 0.1810 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/15\n",
      "50/50 [==============================] - 439s 9s/step - loss: 10.0824 - accuracy: 0.2130 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/15\n",
      "50/50 [==============================] - 442s 9s/step - loss: 8.7051 - accuracy: 0.1110 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=50,\n",
    "        epochs=15,\n",
    "        validation_data=validation_generator,\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5NJTq8GzzHK3"
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate(train_generator, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7hysCECcxYJw"
   },
   "source": [
    "CHALLENGE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sbIU0Cf6wXJe"
   },
   "outputs": [],
   "source": [
    "test_path= os.path.join(data_path, \"test\")\n",
    "\n",
    "test_gallery_path = os.path.join(test_path, 'gallery')\n",
    "test_query_path = os.path.join(test_path, 'query')\n",
    "\n",
    "def imag_load(path) : \n",
    "  temp_images = os.listdir(path)\n",
    "  lista = []\n",
    "  for i in temp_images:\n",
    "    img_tmp = os.path.join(path, i)\n",
    "    lista.append(img_tmp)\n",
    "  return lista\n",
    "\n",
    "gallery = imag_load(gallery_path)\n",
    "query = imag_load(query_path)\n",
    "\n",
    "query_dataset = convert_to_array(query)\n",
    "gallery_dataset = convert_to_array(gallery)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
